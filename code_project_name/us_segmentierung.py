# -*- coding: utf-8 -*-
"""US_Segmentierung.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O0XQcMcv5hLzT2q3BBbpN3DlMnzhxiGm
"""

# Importieren der Daten von Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Ein vortrainiertes Model für YOLOv8 für medizinische Segmentierung
!wget https://github.com/sevdaimany/YOLOv8-Medical-Imaging/raw/master/runs/segment/train/weights/best.pt -O yolov8n-medicalImaging.pt

# Installieren der ultralytics Bibliothek
pip install ultralytics

# Importieren von YOLO
from ultralytics import YOLO

model = YOLO('yolo11n-seg.pt') # load a pretrained model (recommended for training)
#model = YOLO("yolov8n-medicalImaging.pt") # load a pretrained medical imaging model
#model = YOLO("yolo11n-seg.yaml")  # build a new model from YAML

#Augmentation
strong_aug = {
    "dropout": 0.4, #Dropout rate for regularization in classification tasks, preventing overfitting by randomly omitting units during training.
    "hsv_h": 0, #Adjusts the hue of the image
    "hsv_s": 0, #Alters the saturation of the image
    "hsv_v": 0.5, # Modifies the value (brightness) of the image
    "degrees": 30.0, # 30 Rotates the image randomly within the specified degree range
    "translate": 0.1, #Translates the image horizontally and vertically by a fraction of the image size
    "scale": 0.3, #Scales the image by a gain factor
    "shear": 5, #Shears the image by a specified degree
    "perspective": 0.0001, #Applies a random perspective transformation to the image
    "flipud": 0.5, #Flips the image upside down with the specified probability
    "fliplr": 0.7, # 0.5Flips the image left to right with the specified probability
    "bgr": 0, #Flips the image channels from RGB to BGR
    "mosaic": 0, #Combines four training images into one, simulating different scene compositions and object interactions. Highly effective for complex scene understanding.
    "mixup": 0, #Blends two images and their labels, creating a composite image. Enhances the model's ability to generalize by introducing label noise and visual variability.
    "cutmix": 0, #Combines portions of two images, creating a partial blend while maintaining distinct regions. Enhances model robustness by creating occlusion scenarios.
    "erasing": 0, #Classification only. Randomly erases regions of the image during training to encourage the model to focus on less obvious features.
}

no_aug = {
    "dropout": 0,
    "hsv_h": 0,
    "hsv_s": 0,
    "hsv_v": 0,
    "degrees": 0.0,
    "translate": 0.0,
    "scale": 0.0,
    "shear": 0,
    "perspective": 0,
    "flipud": 0.0,
    "fliplr": 0.0,
    "bgr": 0,
    "mosaic": 0,
    "mixup": 0,
    "cutmix": 0,
    "erasing": 0,
}

weak_aug = {
    "dropout": 0.2,
    "hsv_h": 0,
    "hsv_s": 0,
    "hsv_v": 0.1,
    "degrees": 10.0,
    "translate": 0.05,
    "scale": 0.3,
    "shear": 0,
    "perspective": 0,
    "flipud": 0,
    "fliplr": 0.5,
    "bgr": 0,
    "mosaic": 0,
    "mixup": 0,
    "cutmix": 0,
    "erasing": 0,
}

# Einstellung von Trainingsparametern
model.train(
    data='/content/drive/MyDrive/dataset/data.yaml',
    epochs=200,
    imgsz=640,
    #amp=False,
    #lr0=0.0005,
    overlap_mask=False,
    mask_ratio=1,
    batch=32,
    patience=200,
    #freeze=23,
    **strong_aug
    )

#Berechnen IoU
import os
import cv2
import numpy as np
from tqdm import tqdm

model = YOLO("/content/drive/MyDrive/US_Projekt/nopretrained_weak_aug/train/weights/best.pt")  # Adjust path of the model used
# Paths to test images and labels
img_dir = "/content/drive/MyDrive/dataset/test/images/test"
label_dir = "/content/drive/MyDrive/dataset/test/labels/test"

# Helper: Convert YOLO polygon annotation to a binary mask
def polygon_to_mask(img_shape, polygon):
    mask = np.zeros(img_shape, dtype=np.uint8)
    pts = np.array(polygon, np.int32).reshape((-1, 2))
    cv2.fillPoly(mask, [pts], 1)
    return mask

# Store IoUs
ious = []

# Iterate over all test images
for img_file in tqdm(os.listdir(img_dir)):
    if not img_file.endswith((".jpg", ".png", ".jpeg")):
        continue

    # Load image
    img_path = os.path.join(img_dir, img_file)
    image = cv2.imread(img_path)
    h, w = image.shape[:2]

    # Predict with model (resizes to 512 by default)
    results = model.predict(img_path, conf=0.25, save=False)[0]
    pred_masks = results.masks.data.cpu().numpy() if results.masks else []

    # Load ground truth polygons
    label_file = img_file.rsplit(".", 1)[0] + ".txt"
    label_path = os.path.join(label_dir, label_file)
    if not os.path.exists(label_path):
        continue

    with open(label_path, "r") as f:
        lines = f.readlines()

    for line in lines:
        parts = line.strip().split()
        if len(parts) <= 5:
            continue  # skip if no polygon

        polygon = list(map(float, parts[5:]))
        polygon[::2] = [x * w for x in polygon[::2]]  # scale x
        polygon[1::2] = [y * h for y in polygon[1::2]]  # scale y

        gt_mask = polygon_to_mask((h, w), polygon)

        # Match with best predicted mask (resized to original shape)
        best_iou = 0
        for pm in pred_masks:
            pred_mask = (pm > 0.5).astype(np.uint8)
            pred_mask_resized = cv2.resize(pred_mask, (w, h), interpolation=cv2.INTER_NEAREST)

            intersection = np.logical_and(gt_mask, pred_mask_resized).sum()
            union = np.logical_or(gt_mask, pred_mask_resized).sum()
            if union > 0:
                iou = intersection / union
                best_iou = max(best_iou, iou)

        ious.append(best_iou)

# Compute mean IoU
if ious:
    mean_iou = np.mean(ious)
    print(f"\n✅ Mean IoU over {len(ious)} masks: {mean_iou:.4f}")
else:
    print("No IoUs could be calculated — check label/prediction format.")
    
#Berechnen der Metriken mit dem Testdatensatz
!yolo task=segment mode=val model=/content/ runs/segment/train/weights/best.pt
data=/content/drive/MyDrive/dataset/data_test.yaml split=test

# Plotten der train/seg_loss und val/seg_loss werten
import pandas as pd
import matplotlib.pyplot as plt

# Pfad der Datei
path = "/content/ runs/segment/train/results.csv"
path_run = "/content/runs/segment/train/results.csv"
df = pd.read_csv(path)
# Definieren der x-/y-Achse
df = df[["train/seg_loss", "val/seg_loss"]]
df.plot(ylim=(0, 5.5), grid=True)
plt.xlabel("Epoch")
plt.ylabel("Loss")
# Titel des Plots
plt.title("No Pretrained Strong Augmentation")
# Speichern des Plots
plt.savefig('nopretrained_strong_aug.png')


#Model auf Bilder laufen lassen
yolo predict model=/content/runs/segment/train/weights/best.pt
source=/content/drive/MyDrive/US_Projekt/frames line_width=1 conf=0.1
#Model auf video laufen lassen
yolo predict model=/content/runs/segment/train/weights/best.pt
source=/content/drive/MyDrive/US_Projekt/frames/Video_probe line_width=1 conf=0.1 #Path achten
ffmpeg -i runs/segment/predict2/0.avi -vcodec libx264 -crf 23 -preset medium output.mp4
